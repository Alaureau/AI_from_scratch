{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the data stored in the file data FFNN.txt available on the course website. This dataset consists of three columns: x1, x2 and y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"data_FFNN.txt\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:2]\n",
    "Y = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(51,1)\n",
    "Ys = []\n",
    "for y in Y:\n",
    "    if (y == 1):\n",
    "        Ys = np.append(Ys,np.array([0,1]))\n",
    "    else:\n",
    "        Ys = np.append(Ys,np.array([1,0]))\n",
    "Y = Ys.reshape(51,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the aforementioned classifier using the feedforward neural network (FFNN) approach by learning its parameter values using the provided dataset. This FFNN should consist of three layers, in which the hidden layer has 5 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(inputs):\n",
    "    inputs = np.append(0,inputs)\n",
    "    return inputs.reshape(len(inputs),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inputs):\n",
    "    return 1/(1+np.exp(-inputs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(inputs,weights):\n",
    "    outputs = []\n",
    "    for w in weights: #for each neurons\n",
    "        outputs = np.append(outputs,np.dot(inputs.T,w))\n",
    "    return sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,V,W):\n",
    "    X = add_bias(X)       # (3,1)\n",
    "    F = hidden_layer(X,V) # (5,1)\n",
    "    F = add_bias(F)       # (6,1)\n",
    "    Y = hidden_layer(F,W) # (2,1)\n",
    "    return np.argmax(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.random.random_sample((5, 3)) # 5 neurons k, 3 inputs n: x0,x1,x2\n",
    "W = np.random.random_sample((2, 6)) # 2 neurons j, 6 inputs: f0,f1,f2,f3,f4,f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(X[0].reshape(2,1),V,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What are the optimal parameter values for the hidden layer (v) and for the output layer (Ï‰)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_weight(inputs, weights): #Compute for one example  \n",
    "    return inputs*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values(X,V,W):\n",
    "    X = add_bias(X)\n",
    "    X_bar = []\n",
    "    for x in X:\n",
    "        for v in V:\n",
    "            X_bar_bar = np.append(X_bar,inputs_weight(x, v))\n",
    "    F = np.sum(X_bar)\n",
    "    F_bar = sigmoid(F)\n",
    "    for f in F:\n",
    "        for w in W:\n",
    "            F_bar_bar = np.append(F_bar_bar,inputs_weight(f, w))\n",
    "    G = \n",
    "    return X_bar, F, F_bar, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward2(X,V,W):\n",
    "    X = add_bias(X)       # (3,1)\n",
    "    F = hidden_layer(X,V) # (5,1)\n",
    "    F = add_bias(F)       # (6,1)\n",
    "    pred = hidden_layer(F,W) # (2,1)\n",
    "    return pred.reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X,V,W):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        predictions = np.append(predictions,forward2(x.reshape(2,1),V,W))\n",
    "    return predictions.reshape(51,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(y,predictions):\n",
    "    return 0.5*np.sum(np.square(predictions-y)) #SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.531639369670067"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse(Y,get_predictions(X,V,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation():\n",
    "    W = update_W(W, alpha1, F ,pred, Y)\n",
    "    V = update_V(W, V, alpha2, X ,F, pred, Y)\n",
    "    return V,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_W(W, alpha, F, pred, Y):\n",
    "    for w in W: # W(2,6), w(6,)\n",
    "        w = w - alpha*np.sum((pred-y)*pred*(1-pred)*F)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_V():\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show that your classifier can correctly classify for (x 1 , x 2 )=(2, 2) and for (x 1 , x 2 )=(4, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(np.array([[2],[2]]),V,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(np.array([[4],[4]]),V,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
